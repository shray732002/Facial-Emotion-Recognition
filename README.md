# Facial Emotion Recognition

Welcome to the Facial Emotion Recognition GitHub repository! This repository contains a VGG-based deep learning model that predicts the emotion of a human from input images. Additionally, it showcases the results of testing the model on a set of seven sample images.

## Table of Contents

- [About the Project](#about-the-project)
- [Getting Started](#getting-started)
  - [Prerequisites](#prerequisites)
  - [Installation](#installation)
- [Usage](#usage)
  - [Predicting Emotions](#predicting-emotions)
  - [Viewing Test Results](#viewing-test-results)
- [Results](#results)
- [Contributing](#contributing)
- [License](#license)
- [Contact](#contact)

## About the Project

The VGG Emotion Predictor project is aimed at utilizing the power of deep learning to predict the emotions of humans from input images. The VGG model used in this project is a convolutional neural network architecture known for its effectiveness in image classification tasks.

## Getting Started

### Prerequisites

Before you begin, ensure you have the following prerequisites:

- Python 3.x
- TensorFlow (or TensorFlow-GPU) library
- Keras (or Keras-GPU) library
- Numpy library

### Installation

1. Clone the repository:
   ```sh
   git clone [https://github.com/your-username/vgg-emotion-predictor.git](https://github.com/shray732002/Facial-Emotion-Recognition.git)https://github.com/shray732002/Facial-Emotion-Recognition.git
   cd vgg-emotion-predictor
2. Create a virtual environment (optional but recommended):

```sh
conda create --name env_name python=python_version
conda activate env_name
```
  Install required packages:
 ```sh
pip freeze > requirements.txt
```
### Usage
#### Predicting Emotions
